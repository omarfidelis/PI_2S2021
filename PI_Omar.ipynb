{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1907648c",
   "metadata": {},
   "source": [
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/1.1_intro.PNG\" width=\"75%\" height=\"75%\"> <br>\n",
    "### Aluno: Omar Hajime Fidelis\n",
    "### Data: 05/12/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abbffeb",
   "metadata": {},
   "source": [
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/1.2_regras.PNG\" width=\"70%\" height=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78623abd",
   "metadata": {},
   "source": [
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/1.3_BigData.PNG\" width=\"80%\" height=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f1c74",
   "metadata": {},
   "source": [
    "# 1. Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0c3b22",
   "metadata": {},
   "source": [
    "## 1.1. Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aabd0e",
   "metadata": {},
   "source": [
    "Este projeto tem como objetivo a aplicação das técnicas de Ciência de Dados no conjunto de dados (dataset) de \"Wine Quality\".\n",
    "A escolha do dataset está relacionado a continuidade e comparação do processo de desenvolvimento do projeto do semestre anterior.<br><br>\n",
    "O foco principal deste projeto é o desenvolvimento de uma solução de aprendizado de máquina cujo treinamento e processamento deverão ser realizados em ambiente de nuvem (Amazon Web Service - AWS), com processamento distribuído (cluster de computadores), explorando o uso de\n",
    "paralelismo (spark/mapreduce).<br><br>\n",
    "Além do ambiente distribuído, aplicou-se técnicas de machine learning (normalização, pipeline, cross validation), e alguns algoritmos de classificação para avaliação de performance e resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ebe1aa",
   "metadata": {},
   "source": [
    "## 1.2. Descrição Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855e6b57",
   "metadata": {},
   "source": [
    "A base de dados consolidada é composta por 1599 amostra de vinho tinto e 4898 amostra de vinho branco, totalizando 6497 amostra e descritas pela coluna \"style\". O dataset foi criado Paulo Cortez (Univ. Minho), António Cerdeira, Fernando Almeida, Telmo Matos and José Reis em 2009.<br>\n",
    "Cada linha da base de dados é uma amostra de vinho com suas medições fisico-químicas, tipo do vinho (vermelho ou branco) e a nota/avaliação de especialistas.<br>\n",
    "Neste projeto, consideramos a análise para a classificação do vinho, podendo ser \"tinto\" ou \"branco\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60b6882",
   "metadata": {},
   "source": [
    "## 1.3. Detalhamento dos atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea814678",
   "metadata": {},
   "source": [
    "**fixed_acidity = Acidez Fixa:** ácido não volátil encontrado no vinho, que é tartárico, málico, cítrico e succínico. Todos esses ácidos são originários das uvas, com exceção do ácido succínico, que é produzido pela levedura durante o processo de fermentação<br><br>\n",
    "**volatile_acidity = Acidez volátil:** os elementos ácidos de um vinho que são gasosos, em vez de líquidos e, portanto, podem ser sentidos como um cheiro, mostrando um aroma, em vez de encontrados no palato<br><br>\n",
    "**citric_acid = Ácido cítrico:** um ácido orgânico fraco, frequentemente usado como conservante natural ou aditivo para alimentos ou bebidas para adicionar um sabor azedo e frescor aos alimentos<br><br>\n",
    "**residual_sugar = Açúcar residual:** a quantidade de açúcar remanescente após a parada da fermentação, é raro encontrar vinhos com menos de 1 grama / litro e vinhos com mais de 45 gramas / litro são considerados doces<br><br>\n",
    "**chlorides = Cloretos:** a quantidade de sal no vinho<br><br>\n",
    "**free_sulfur_dioxide = Dióxido de Enxofre Livre (SO2):** o SO2 é usado em todas as fases do processo de vinificação para prevenir a oxidação e o crescimento microbiano. Quantidades excessivas de SO2 podem inibir a fermentação e causar efeitos sensoriais indesejáveis<br><br>\n",
    "**total_sulfur_dioxide = Dióxido de Enxofre Total:** quantidade das formas livre e ligada de S02S02; em baixas concentrações, SO2SO2 é principalmente indetectável no vinho, mas em concentrações de SO2SO2 livre acima de 50 ppm, SO2SO2 torna-se evidente no nariz e no sabor do vinho<br><br>\n",
    "**density = Densidade:** a densidade é próxima à da água, dependendo da porcentagem de álcool e açúcar<br><br>\n",
    "**pH:** produtores de vinho usam o pH como forma de medir a maturação em relação à acidez. Vinhos de pH baixo terão gosto ácido e crocante, enquanto vinhos de pH mais alto são mais suscetíveis ao crescimento bacteriano. A maioria do pH do vinho está em torno de 3 ou 4<br><br>\n",
    "**sulphates = Sulfatos:** aditivo do vinho que pode contribuir para os níveis de gás de dióxido de enxofre (S02S02), que atua como um antimicrobiano e antioxidante<br><br>\n",
    "**alcohol = Álcool:** o teor de álcool do vinho em percentual<br><br>\n",
    "**quality = Qualidade:** notas/avaliações realizadas por no mínimo 3 especialistas em vinhos<br><br>\n",
    "**style = Tipo:** Tipo do Vino (Vermelho ou Branco)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75897ea0",
   "metadata": {},
   "source": [
    "# 2. Infraestrutura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4003afd0",
   "metadata": {},
   "source": [
    "## 2.1. Infraestrutura AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a85039",
   "metadata": {},
   "source": [
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/2.1_AWS_arquitetura.PNG\" width=\"70%\" height=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10e5e0d",
   "metadata": {},
   "source": [
    "## 2.2. AWS Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd383793",
   "metadata": {},
   "source": [
    "### 2.2.1. Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e853f00",
   "metadata": {},
   "source": [
    "Apache Spark is a distributed processing framework and programming model that helps you do machine learning, stream processing, or graph analytics using Amazon EMR clusters. Similar to Apache Hadoop, Spark is an open-source, distributed processing system commonly used for big data workloads. However, Spark has several notable differences from Hadoop MapReduce. Spark has an optimized directed acyclic graph (DAG) execution engine and actively caches data in-memory, which can boost performance, especially for certain algorithms and interactive queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fae6ef2",
   "metadata": {},
   "source": [
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/2.2_EMR_Spark.PNG\" width=\"70%\" height=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c3081c",
   "metadata": {},
   "source": [
    "### 2.2.2. Apache Hive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972d2006",
   "metadata": {},
   "source": [
    "Hive is an open-source, data warehouse, and analytic package that runs on top of a Hadoop cluster. Hive scripts use an SQL-like language called Hive QL (query language) that abstracts programming models and supports typical data warehouse interactions. Hive enables you to avoid the complexities of writing Tez jobs based on directed acyclic graphs (DAGs) or MapReduce programs in a lower level computer language, such as Java."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa63943",
   "metadata": {},
   "source": [
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/2.3_EMR_Hive.PNG\" width=\"70%\" height=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a25bd2",
   "metadata": {},
   "source": [
    "### 2.2.3. Apache Livy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c9a649",
   "metadata": {},
   "source": [
    "Livy enables interaction over a REST interface with an EMR cluster running Spark. You can use the REST interface or an RPC client library to submit Spark jobs or snippets of Spark code, retrieve results synchronously or asynchronously, and manage Spark Context. For more information, see the Apache Livy website. Livy is included in Amazon EMR release version 5.9.0 and later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a14396",
   "metadata": {},
   "source": [
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/2.4_EMR_Livy.PNG\" width=\"70%\" height=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f3825f",
   "metadata": {},
   "source": [
    "### 2.2.4. Amazon EMR Notebook based on Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01e713f",
   "metadata": {},
   "source": [
    "EMR Notebooks is a Jupyter Notebook environment built in to the Amazon EMR console that allows you to quickly create Jupyter notebooks, attach them to Spark clusters, and then open the Jupyter Notebook editor in the console to remotely run queries and code. An EMR notebook is saved in Amazon S3 independently from clusters for durable storage, quick access, and flexibility. You can have multiple notebooks open, attach multiple notebooks to a single cluster, and re-use a notebook on different clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0fa867",
   "metadata": {},
   "source": [
    "### 2.2.4. Amazon EMR Notebook Arquitetura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e95d042",
   "metadata": {},
   "source": [
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/2.6_EMR_JupyterHub_Arqchitecture.PNG\" width=\"70%\" height=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b481e19",
   "metadata": {},
   "source": [
    "## 2.3. Create EMR Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce53c364",
   "metadata": {},
   "source": [
    "### Lista de aplicações do Cluster\n",
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/3.1_Create_cluster_step_1.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445f6088",
   "metadata": {},
   "source": [
    "### Hardware Configuration\n",
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/3.2_Create_cluster_step_2.1.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b75657",
   "metadata": {},
   "source": [
    "### Hardware Description\n",
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/3.3_Create_cluster_step_2.2.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be75e2e",
   "metadata": {},
   "source": [
    "### Habilitando Cluster Scaling\n",
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/3.4_Create_cluster_step_2.3.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9135620a",
   "metadata": {},
   "source": [
    "### Aumento hardware configuration\n",
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/3.7_Create_cluster_step_2.4HP.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48bfb8b",
   "metadata": {},
   "source": [
    "### Definição de Bucket de LOG\n",
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/3.8_Create_cluster_step_3.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb07eaa",
   "metadata": {},
   "source": [
    "### Configuração padrão (key, role, profile, etc.)\n",
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/3.9_Create_cluster_step_4.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08d720b",
   "metadata": {},
   "source": [
    "### Running server\n",
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/3.11_EMR_cluster_running.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88779f16",
   "metadata": {},
   "source": [
    "### Running Jupyter Notebook\n",
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/3.13_Jupyter_started.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325ea088",
   "metadata": {},
   "source": [
    "## 2.4. Hardware Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c1412a",
   "metadata": {},
   "source": [
    "### Summary Configuration\n",
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/4.1_Summary_configuration.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b257047",
   "metadata": {},
   "source": [
    "### Hardware Configuration\n",
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/4.2_Hardware_configuration.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e872e530",
   "metadata": {},
   "source": [
    "### Application Configuration\n",
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/4.3_Application_configuration.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad3e7a0",
   "metadata": {},
   "source": [
    "### Spark Sessions\n",
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/4.4_Spark_Sessions.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606ba73",
   "metadata": {},
   "source": [
    "# 3. Preparação do ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1232d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Spark Session\n",
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2542a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Strucuture\n",
    "schema = StructType([ \\\n",
    "                    StructField(\"Acidez_Fixa\", FloatType(), True), \\\n",
    "                    StructField(\"Acidez_Volatil\", FloatType(), True), \\\n",
    "                    StructField(\"Acido_Citrico\", FloatType(), True), \\\n",
    "                    StructField(\"Acucar_Residual\", FloatType(), True), \\\n",
    "                    StructField(\"Cloreto_Sodio\", FloatType(), True), \\\n",
    "                    StructField(\"Dioxido_Enxofre_Livre\", FloatType(), True), \\\n",
    "                    StructField(\"Dioxido_Enxofre_Total\", FloatType(), True), \\\n",
    "                    StructField(\"Densidade\", FloatType(), True), \\\n",
    "                    StructField(\"pH\", FloatType(), True), \\\n",
    "                    StructField(\"Sulfato\", FloatType(), True), \\\n",
    "                    StructField(\"Alcool\", FloatType(), True), \\\n",
    "                    StructField(\"Qualidade\", FloatType(), True), \\\n",
    "                    StructField(\"Tipo\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff157752",
   "metadata": {},
   "source": [
    "## 3.1. Preparação dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74014fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset from S3 Bucket\n",
    "df = spark.read.schema(schema).option(\"header\",\"true\").csv(r\"s3n://bucket.omar/dataset/wine_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335e6d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae68cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Staset Schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059bb938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No missing values\n",
    "df.select(df.columns).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0489b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VIEW for dataset\n",
    "df.createOrReplaceTempView(\"table_wine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37844601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidede de amostrar por tipo de vinho\n",
    "df2 = spark.sql('SELECT count(*) as Total, Tipo from table_wine group by Tipo')\n",
    "df2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc751496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor máximo de cada atributo\n",
    "df2 = spark.sql('SELECT max(Acidez_Fixa),\\\n",
    "                        max(Acidez_Volatil),\\\n",
    "                        max(Acido_Citrico),\\\n",
    "                        max(Acucar_Residual),\\\n",
    "                        max(Cloreto_Sodio),\\\n",
    "                        max(Dioxido_Enxofre_Livre),\\\n",
    "                        max(Dioxido_Enxofre_Total),\\\n",
    "                        max(Densidade),\\\n",
    "                        max(pH),\\\n",
    "                        max(Sulfato),\\\n",
    "                        max(Alcool),\\\n",
    "                        max(Qualidade) from table_wine')\n",
    "df2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08da78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor mínimo de cada atributo\n",
    "df2 = spark.sql('SELECT min(Acidez_Fixa),\\\n",
    "                        min(Acidez_Volatil),\\\n",
    "                        min(Acido_Citrico),\\\n",
    "                        min(Acucar_Residual),\\\n",
    "                        min(Cloreto_Sodio),\\\n",
    "                        min(Dioxido_Enxofre_Livre),\\\n",
    "                        min(Dioxido_Enxofre_Total),\\\n",
    "                        min(Densidade),\\\n",
    "                        min(pH),\\\n",
    "                        min(Sulfato),\\\n",
    "                        min(Alcool),\\\n",
    "                        min(Qualidade) from table_wine')\n",
    "df2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor médio de cada atributo\n",
    "df2 = spark.sql('SELECT avg(Acidez_Fixa),\\\n",
    "                        avg(Acidez_Volatil),\\\n",
    "                        avg(Acido_Citrico),\\\n",
    "                        avg(Acucar_Residual),\\\n",
    "                        avg(Cloreto_Sodio),\\\n",
    "                        avg(Dioxido_Enxofre_Livre),\\\n",
    "                        avg(Dioxido_Enxofre_Total),\\\n",
    "                        avg(Densidade),\\\n",
    "                        avg(pH),\\\n",
    "                        avg(Sulfato),\\\n",
    "                        avg(Alcool),\\\n",
    "                        avg(Qualidade) from table_wine')\n",
    "df2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e66d005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 amostras melhor avaliadas\n",
    "df2 = spark.sql('SELECT Qualidade, Tipo from table_wine order by Qualidade desc limit 10')\n",
    "df2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382f045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de amostras por avaliação e label\n",
    "df2 = spark.sql('SELECT count(*) as Total, Qualidade, Tipo\\\n",
    "                    from table_wine\\\n",
    "                    group by Qualidade, Tipo\\\n",
    "                    order by Qualidade desc, Tipo')\n",
    "df2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63973d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform categorical atrribute (\"Tipo\") to bynary attribute \n",
    "df = df.withColumn('label', col('Tipo') == 'red')\n",
    "df = df.drop('Tipo')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec49ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast bynary attribute to numerical attribute named \"label\" (standard)\n",
    "from pyspark.sql.types import IntegerType\n",
    "df = df.withColumn(\"label\",col(\"label\").cast(IntegerType()))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8941f2b1",
   "metadata": {},
   "source": [
    "# 4. Processamento (Machine Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e207ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraies - Machine Learning\n",
    "from pyspark.ml.feature import VectorAssembler, Normalizer, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression, NaiveBayes, LinearSVC, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56226d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset (training 80% and test 20%)\n",
    "training, test = df.randomSplit([0.8, 0.2], seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4259cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Assembler\n",
    "assembler = VectorAssembler(inputCols=['Acidez_Fixa','Acidez_Volatil','Acido_Citrico','Acucar_Residual',\\\n",
    "                                       'Cloreto_Sodio','Dioxido_Enxofre_Livre','Dioxido_Enxofre_Total',\\\n",
    "                                       'Densidade','pH','Sulfato','Alcool','Qualidade'], \\\n",
    "                            outputCol=\"inputFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c304df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaler (Normalize)\n",
    "#scaler = Normalizer(inputCol = \"inputFeatures\", outputCol = \"features\")\n",
    "scaler = StandardScaler(inputCol = \"inputFeatures\", outputCol = \"features\", withStd=True, withMean=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1db679",
   "metadata": {},
   "source": [
    "## 4.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51650672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Creation\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc1e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Pipeline\n",
    "#pipeline_lr = Pipeline(stages = [assembler, lr])\n",
    "pipeline_lr = Pipeline(stages = [assembler, scaler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e0dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "paramgrid_lr = ParamGridBuilder().addGrid(lr.regParam, [0.0, 0,1]).addGrid(lr.maxIter, [10]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504efca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "evaluator_lr = MulticlassClassificationEvaluator(metricName = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1dadd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "crossval_lr = CrossValidator(estimator = pipeline_lr, estimatorParamMaps = paramgrid_lr, \\\n",
    "                             evaluator = evaluator_lr, numFolds = 3, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f4b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation\n",
    "cvModel_lr = crossval_lr.fit(training)\n",
    "evaluator_lr.evaluate(cvModel_lr.transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f514d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "evaluator_lr = MulticlassClassificationEvaluator(metricName = \"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "crossval_lr = CrossValidator(estimator = pipeline_lr, estimatorParamMaps = paramgrid_lr, \\\n",
    "                             evaluator = evaluator_lr, numFolds = 3, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation\n",
    "cvModel_lr = crossval_lr.fit(training)\n",
    "evaluator_lr.evaluate(cvModel_lr.transform(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f7efcc",
   "metadata": {},
   "source": [
    "## 4.2. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Creation\n",
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f8e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Pipeline\n",
    "#pipeline_nb = Pipeline(stages = [assembler, nb])\n",
    "pipeline_nb = Pipeline(stages = [assembler, scaler, nb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce69fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "paramgrid_nb = ParamGridBuilder().build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c7773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "evaluator_nb = MulticlassClassificationEvaluator(metricName = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd95ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "crossval_nb = CrossValidator(estimator = pipeline_nb, estimatorParamMaps = paramgrid_nb, \\\n",
    "                             evaluator = evaluator_nb, numFolds = 3, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bcfaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation\n",
    "cvModel_nb = crossval_nb.fit(training)\n",
    "evaluator_nb.evaluate(cvModel_nb.transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c37e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "evaluator_nb = MulticlassClassificationEvaluator(metricName = \"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed200fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "crossval_nb = CrossValidator(estimator = pipeline_nb, estimatorParamMaps = paramgrid_nb, \\\n",
    "                             evaluator = evaluator_nb, numFolds = 3, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace7313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation\n",
    "cvModel_nb = crossval_nb.fit(training)\n",
    "evaluator_nb.evaluate(cvModel_nb.transform(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c34f6d",
   "metadata": {},
   "source": [
    "## 4.3. Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16c4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Creation\n",
    "lsvc = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6427cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Pipeline\n",
    "#pipeline_lsvc = Pipeline(stages = [assembler, lsvc])\n",
    "pipeline_lsvc = Pipeline(stages = [assembler, scaler, lsvc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca51eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "paramgrid_lsvc = ParamGridBuilder().build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f5596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "evaluator_lsvc = MulticlassClassificationEvaluator(metricName = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f68f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "crossval_lsvc = CrossValidator(estimator = pipeline_lsvc, estimatorParamMaps = paramgrid_lsvc, \\\n",
    "                             evaluator = evaluator_lsvc, numFolds = 3, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0784d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation\n",
    "cvModel_lsvc = crossval_lsvc.fit(training) \n",
    "evaluator_lsvc.evaluate(cvModel_lsvc.transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01332e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "evaluator_lsvc = MulticlassClassificationEvaluator(metricName = \"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7800f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "crossval_lsvc = CrossValidator(estimator = pipeline_lsvc, estimatorParamMaps = paramgrid_lsvc, \\\n",
    "                             evaluator = evaluator_lsvc, numFolds = 3, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb914057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation\n",
    "cvModel_lsvc = crossval_lsvc.fit(training) \n",
    "evaluator_lsvc.evaluate(cvModel_lsvc.transform(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b37453",
   "metadata": {},
   "source": [
    "## 4.4. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770269e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Creation\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f78990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Pipeline\n",
    "#pipeline_rf = Pipeline(stages = [assembler, rf])\n",
    "pipeline_rf = Pipeline(stages = [assembler, scaler, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc3ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "paramgrid_rf = ParamGridBuilder().build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e6813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "evaluator_rf = MulticlassClassificationEvaluator(metricName = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cd27cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "crossval_rf = CrossValidator(estimator = pipeline_rf, estimatorParamMaps = paramgrid_rf, \\\n",
    "                             evaluator = evaluator_rf, numFolds = 3, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation\n",
    "cvModel_rf = crossval_rf.fit(training) \n",
    "evaluator_rf.evaluate(cvModel_rf.transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a0670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "evaluator_rf = MulticlassClassificationEvaluator(metricName = \"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c3f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "crossval_rf = CrossValidator(estimator = pipeline_rf, estimatorParamMaps = paramgrid_rf, \\\n",
    "                             evaluator = evaluator_rf, numFolds = 3, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d12e8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation\n",
    "cvModel_rf = crossval_rf.fit(training) \n",
    "evaluator_rf.evaluate(cvModel_rf.transform(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bd3dc2",
   "metadata": {},
   "source": [
    "## 4.5. Gradient Boosted Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Creation\n",
    "gbt = GBTClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a970651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Pipeline\n",
    "#pipeline_gbt = Pipeline(stages = [assembler, gbt])\n",
    "pipeline_gbt = Pipeline(stages = [assembler, scaler, gbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1133ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "paramgrid_gbt = ParamGridBuilder().build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d7964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "evaluator_gbt = MulticlassClassificationEvaluator(metricName = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c31f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "crossval_gbt = CrossValidator(estimator = pipeline_gbt, estimatorParamMaps = paramgrid_gbt, \\\n",
    "                              evaluator = evaluator_gbt, numFolds = 3, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f892b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation\n",
    "cvModel_gbt = crossval_gbt.fit(training) \n",
    "evaluator_gbt.evaluate(cvModel_gbt.transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a36b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "evaluator_gbt = MulticlassClassificationEvaluator(metricName = \"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c0ae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "crossval_gbt = CrossValidator(estimator = pipeline_gbt, estimatorParamMaps = paramgrid_gbt, \\\n",
    "                              evaluator = evaluator_gbt, numFolds = 3, seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3447446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation\n",
    "cvModel_gbt = crossval_gbt.fit(training) \n",
    "evaluator_gbt.evaluate(cvModel_gbt.transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sparkContext.stop()\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecbaafe",
   "metadata": {},
   "source": [
    "## 4.6. Tempo de Execução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e8b4c2",
   "metadata": {},
   "source": [
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/6.1_Tempos.PNG\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc47fe4",
   "metadata": {},
   "source": [
    "## 4.7. Consolidado dos Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9637a713",
   "metadata": {},
   "source": [
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/6.2_Resultados.PNG\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04df4ffa",
   "metadata": {},
   "source": [
    "(*) Normalizer is a Transformer which transforms a dataset of Vector rows, normalizing each Vector to have unit norm. It takes parameter p, which specifies the p-norm used for normalization. (p=2 by default.) This normalization can help standardize your input data and improve the behavior of learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ffe40",
   "metadata": {},
   "source": [
    "(*) StandardScaler transforms a dataset of Vector rows, normalizing each feature to have unit standard deviation and/or zero mean. It takes parameters:<br>\n",
    "withStd: True by default. Scales the data to unit standard deviation.<br>\n",
    "withMean: False by default. Centers the data with mean before scaling. It will build a dense output, so take care when applying to sparse input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1774d893",
   "metadata": {},
   "source": [
    "# 5. Referência\n",
    "<br>\n",
    "Página do Professor Paulo Cortez<br>\n",
    "http://www3.dsi.uminho.pt/pcortez/Home.html<br>\n",
    "<br>\n",
    "Página de download da base de dados (dataset winequality.zip)<br>\n",
    "http://www3.dsi.uminho.pt/pcortez/wine/<br>\n",
    "<br>\n",
    "Spark Apache<br>\n",
    "https://spark.apache.org/<br>\n",
    "<br>\n",
    "Apache Spark<br>\n",
    "https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark.html<br>\n",
    "<br>\n",
    "Create a cluster with Spark<br>\n",
    "https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-launch.html<br>\n",
    "<br>\n",
    "Apache Hive<br>\n",
    "https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hive.html<br>\n",
    "<br>\n",
    "Apache Livy<br>\n",
    "https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-livy.html<br>\n",
    "<br>\n",
    "Amazon EMR Notebook based on Jupyter Notebook<br>\n",
    "https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-jupyter-emr-managed-notebooks.html<br>\n",
    "<br>\n",
    "Spark 3.2.0 - ML Pipelines<br>\n",
    "https://spark.apache.org/docs/latest/ml-guide.html<br>\n",
    "<br>\n",
    "Machine Learning with PySpark and Amazon EMR<br>\n",
    "https://towardsdatascience.com/machine-learning-with-pyspark-and-amazon-emr-3149dbc847ae<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2142ea41",
   "metadata": {},
   "source": [
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/1.4_apresentacao.PNG\" width=\"70%\" height=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6725d677",
   "metadata": {},
   "source": [
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/1.5_entregaveis.PNG\" width=\"70%\" height=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f64199e",
   "metadata": {},
   "source": [
    "<img src=\"https://alunos.s3.amazonaws.com/omar.fidelis/images/1.6_criterios.PNG\" width=\"70%\" height=\"70%\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
